{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, InputExample, models, evaluation, losses\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and saving to CSV\n",
    "def get_data_csv():\n",
    "    df_data = pd.read_csv('data.csv')\n",
    "    df_data.to_csv('data.csv', index=False, encoding='utf-8')\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = get_data_csv()\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"cvs\"] = df_data[\"curriculos\"].apply(lambda x: re.sub('\\d+', '', x))\n",
    "df_data[\"jobs\"] = df_data[\"vagas\"].apply(lambda x: re.sub('\\d+', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming relevance scores into similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.set_output(transform='pandas');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"scores\"] = min_max_scaler.fit_transform(df_data[\"notas\"].values.reshape(-1, 1))\n",
    "# 1 -> 0.00\n",
    "# 2 -> 0.25\n",
    "# 3 -> 0.50\n",
    "# 4 -> 0.75\n",
    "# 5 -> 1.00\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unnecessary columns\n",
    "df_data.drop(columns=['curriculos', 'vagas', 'notas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_examples = []\n",
    "for index, row in df_data.iterrows():\n",
    "    data_examples.append(InputExample(texts=[row['cvs'], row['jobs']], label=row['scores']))\n",
    "\n",
    "# Splitting the data into 60% for training, 20% for validation and 20% for tests.\n",
    "data_examples = shuffle(data_examples, random_state=42)\n",
    "train_index = int(len(data_examples) * 0.6)\n",
    "val_index = int(len(data_examples) * 0.2)\n",
    "\n",
    "train_examples = data_examples[:train_index]\n",
    "val_examples = data_examples[train_index:train_index+val_index]\n",
    "test_examples = data_examples[train_index+val_index:]\n",
    "\n",
    "# Creating PyTorch's DataLoader\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "\n",
    "word_embedding_model = models.Transformer(checkpoint, cache_dir=f'model/{checkpoint}')\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode='cls')\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(val_examples, name='sbert')\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=5, evaluator=evaluator, show_progress_bar=True, output_path=f'model_FT/{checkpoint}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a job recommendation system for a cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test = 'Nome: Laura Costa - Objetivo: Busco uma posição como Analista Econômico, onde posso aplicar minha formação acadêmica em Economia e aprimorar minhas habilidades em análise econômica. Formação Acadêmica: Bacharelado em Economia - Universidade Federal de Estado Y (-) Experiência Profissional: Assistente de Análise Econômica - Empresa de Consultoria Econômica LTDA - Cidade Financeira, Estado Y (-Presente) Coleta de dados econômicos. Auxílio na elaboração de relatórios e análises. Habilidades: Conhecimentos intermediários em análise econômica. Familiaridade com ferramentas como Excel e SPSS. Idiomas: Inglês: Avançado Espanhol: Básico'\n",
    "\n",
    "jobs_test = list(set([test_example.texts[1] for test_example in test_examples]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_embedding = model.encode(cv_test)\n",
    "jobs_embedding = [model.encode(vaga) for vaga in jobs_test]\n",
    "similarity_score = util.cos_sim(cv_embedding, jobs_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the pairs cv-vacancy with the highest cosine similarity score\n",
    "pairs = []\n",
    "for index, score in enumerate(similarity_score[0]):\n",
    "    pairs.append({\"index\": index, \"score\": score})\n",
    "\n",
    "# Sort the pairs by scores in descending order\n",
    "pairs = sorted(pairs, key=lambda x: x[\"score\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' CV: {cv_test} \\n\\n')\n",
    "for pair in pairs[0:5]:\n",
    "    print(f' Job: {jobs_test[pair[\"index\"]]} \\n Predicted similarity score after fine-tuning: {pair[\"score\"]} \\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
